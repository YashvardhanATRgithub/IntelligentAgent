"""
Reflection Module - Stanford-level insight generation

This module generates higher-level insights from agent memories.
Based on Stanford's reflect.py (~9KB) from generative_agents.

Key concepts:
1. Triggered when accumulated importance exceeds threshold
2. Uses LLM to synthesize patterns from recent memories
3. Generates 2-3 high-level insights per reflection
4. Reflections are stored as high-importance memories (8-9)
5. Influences future planning and decision-making

Reflection types:
- Self-reflection: Insights about own behavior patterns
- Social reflection: Insights about relationships/other agents  
- Situational reflection: Insights about environment/events
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from enum import Enum
import asyncio
import json
import re


class ReflectionType(Enum):
    """Types of reflections an agent can generate"""
    SELF = "self"                   # About own behavior/feelings
    SOCIAL = "social"               # About relationships/others
    SITUATIONAL = "situational"     # About environment/events
    GOAL = "goal"                   # About objectives/plans
    INSIGHT = "insight"             # General observations


@dataclass
class Reflection:
    """
    A reflection generated by an agent.
    Higher importance than regular memories.
    """
    content: str                        # The insight content
    reflection_type: ReflectionType     # Category
    timestamp: datetime = field(default_factory=datetime.now)
    importance: float = 8.0             # Reflections are high importance
    
    # What memories this reflection is based on
    source_memory_ids: List[str] = field(default_factory=list)
    
    # Generated questions for further reflection
    follow_up_questions: List[str] = field(default_factory=list)
    
    def __repr__(self):
        return f"Reflection({self.reflection_type.value}: {self.content[:60]}...)"


class ReflectionEngine:
    """
    Stanford-level reflection system.
    
    Generates higher-order insights by:
    1. Monitoring accumulated importance of new memories
    2. When threshold exceeded, triggering reflection
    3. Using LLM to synthesize insights from recent memories
    4. Storing reflections as high-importance memories
    5. Generating questions for deeper reflection
    """
    
    # Reflection triggers (Stanford-style thresholds)
    IMPORTANCE_THRESHOLD = 50.0      # Accumulated importance to trigger reflection
    MIN_MEMORIES_FOR_REFLECTION = 5  # Need at least this many memories
    MAX_MEMORIES_TO_CONSIDER = 20    # Don't overwhelm LLM
    REFLECTION_COOLDOWN_STEPS = 10   # Minimum steps between reflections
    
    def __init__(self):
        self.accumulated_importance: Dict[str, float] = {}  # Per agent
        self.last_reflection_step: Dict[str, int] = {}      # Per agent
        self.reflection_count: Dict[str, int] = {}          # Per agent
    
    def should_reflect(
        self, 
        agent_name: str, 
        current_step: int,
        recent_memories: List[Dict]
    ) -> bool:
        """
        Determine if agent should reflect based on accumulated importance.
        
        Args:
            agent_name: Name of the agent
            current_step: Current simulation step
            recent_memories: Recent memories with importance scores
        
        Returns:
            True if reflection should be triggered
        """
        # Check cooldown
        last_step = self.last_reflection_step.get(agent_name, 0)
        if current_step - last_step < self.REFLECTION_COOLDOWN_STEPS:
            return False
        
        # Check minimum memories
        if len(recent_memories) < self.MIN_MEMORIES_FOR_REFLECTION:
            return False
        
        # Calculate accumulated importance since last reflection
        accumulated = sum(m.get("importance", 5.0) for m in recent_memories)
        
        # Store for tracking
        self.accumulated_importance[agent_name] = accumulated
        
        return accumulated >= self.IMPORTANCE_THRESHOLD
    
    def add_importance(self, agent_name: str, importance: float):
        """Add importance to agent's accumulated total"""
        current = self.accumulated_importance.get(agent_name, 0.0)
        self.accumulated_importance[agent_name] = current + importance
    
    def reset_importance(self, agent_name: str, current_step: int):
        """Reset accumulated importance after reflection"""
        self.accumulated_importance[agent_name] = 0.0
        self.last_reflection_step[agent_name] = current_step
        self.reflection_count[agent_name] = self.reflection_count.get(agent_name, 0) + 1
    
    async def generate_reflection(
        self,
        agent_name: str,
        agent_role: str,
        personality_summary: str,
        recent_memories: List[Dict],
        llm_client: Any,
        current_step: int = 0
    ) -> List[Reflection]:
        """
        Generate reflections using LLM.
        
        Args:
            agent_name: Name of the agent
            agent_role: Role of the agent
            personality_summary: Brief personality description
            recent_memories: Recent memories to reflect on
            llm_client: LLM client for generation
            current_step: Current simulation step
        
        Returns:
            List of generated Reflection objects
        """
        if not llm_client:
            return self._generate_fallback_reflections(agent_name, recent_memories)
        
        # Prepare memories for prompt
        memories_text = self._format_memories_for_prompt(recent_memories)
        
        # Build reflection prompt (Stanford-style)
        prompt = f"""You are {agent_name}, a {agent_role} at ISRO's Aryabhata Station on the Moon.

{personality_summary}

Based on these recent experiences and observations:

{memories_text}

Generate 2-3 high-level insights or reflections. Focus on:
1. Patterns in behavior (yours or others')
2. Changes in relationships
3. Important realizations about the situation
4. Questions that arise from these experiences

For each reflection, indicate if it's about:
- SELF: Your own behavior/feelings
- SOCIAL: Relationships with others
- SITUATIONAL: The environment/events
- GOAL: Your objectives/plans

Respond in this exact JSON format:
{{
    "reflections": [
        {{
            "type": "SELF|SOCIAL|SITUATIONAL|GOAL",
            "content": "The insight or reflection",
            "importance": 8,
            "follow_up_question": "A question this raises"
        }}
    ]
}}
"""
        
        try:
            response = await llm_client.generate_content_async(prompt)
            reflections = self._parse_reflection_response(response.text, recent_memories)
            
            # Reset importance after successful reflection
            self.reset_importance(agent_name, current_step)
            
            return reflections
            
        except Exception as e:
            print(f"Reflection error for {agent_name}: {e}")
            return self._generate_fallback_reflections(agent_name, recent_memories)
    
    def _format_memories_for_prompt(self, memories: List[Dict]) -> str:
        """Format memories for LLM prompt"""
        lines = []
        for i, mem in enumerate(memories[:self.MAX_MEMORIES_TO_CONSIDER], 1):
            content = mem.get("content", "")
            mem_type = mem.get("memory_type", "observation")
            importance = mem.get("importance", 5)
            timestamp = mem.get("timestamp", "")
            
            # Format timestamp if present
            time_str = ""
            if timestamp:
                try:
                    if isinstance(timestamp, str):
                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        time_str = f"[{dt.strftime('%H:%M')}] "
                except:
                    pass
            
            lines.append(f"{i}. {time_str}({mem_type}, importance={importance}) {content}")
        
        return "\n".join(lines)
    
    def _parse_reflection_response(
        self, 
        response_text: str,
        source_memories: List[Dict]
    ) -> List[Reflection]:
        """Parse LLM response into Reflection objects"""
        reflections = []
        source_ids = [m.get("id", "") for m in source_memories if m.get("id")]
        
        try:
            # Extract JSON from response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                
                for ref_data in data.get("reflections", []):
                    # Map type string to enum
                    type_str = ref_data.get("type", "INSIGHT").upper()
                    try:
                        ref_type = ReflectionType[type_str]
                    except KeyError:
                        ref_type = ReflectionType.INSIGHT
                    
                    reflection = Reflection(
                        content=ref_data.get("content", ""),
                        reflection_type=ref_type,
                        importance=float(ref_data.get("importance", 8.0)),
                        source_memory_ids=source_ids[:5],  # Link to source memories
                        follow_up_questions=[ref_data.get("follow_up_question", "")]
                    )
                    
                    if reflection.content:
                        reflections.append(reflection)
        
        except json.JSONDecodeError as e:
            print(f"JSON parse error in reflection: {e}")
        except Exception as e:
            print(f"Error parsing reflection: {e}")
        
        return reflections if reflections else self._generate_fallback_reflections("", [])
    
    def _generate_fallback_reflections(
        self, 
        agent_name: str,
        recent_memories: List[Dict]
    ) -> List[Reflection]:
        """Generate simple reflections without LLM"""
        reflections = []
        
        # Count interaction types
        dialogue_count = sum(1 for m in recent_memories if "said" in m.get("content", "").lower())
        work_count = sum(1 for m in recent_memories if "work" in m.get("content", "").lower())
        
        if dialogue_count >= 3:
            reflections.append(Reflection(
                content=f"I've been having many conversations lately. Social connections are important here.",
                reflection_type=ReflectionType.SOCIAL,
                importance=7.0
            ))
        
        if work_count >= 3:
            reflections.append(Reflection(
                content=f"I've been focused on work. Perhaps I should take a break soon.",
                reflection_type=ReflectionType.SELF,
                importance=6.0
            ))
        
        if not reflections:
            reflections.append(Reflection(
                content="Time passes differently on the Moon. Each day brings new challenges.",
                reflection_type=ReflectionType.SITUATIONAL,
                importance=6.0
            ))
        
        return reflections
    
    def get_reflection_stats(self, agent_name: str) -> Dict[str, Any]:
        """Get reflection statistics for an agent"""
        return {
            "accumulated_importance": self.accumulated_importance.get(agent_name, 0.0),
            "last_reflection_step": self.last_reflection_step.get(agent_name, 0),
            "total_reflections": self.reflection_count.get(agent_name, 0),
            "threshold": self.IMPORTANCE_THRESHOLD
        }


# Global reflection engine instance
reflection_engine = ReflectionEngine()
